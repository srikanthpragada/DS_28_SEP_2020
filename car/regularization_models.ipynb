{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>A model will have a low accuracy if it is overfitting. </li>\n",
    "<li>Overfitting occurs when model is trying too hard to capture the noise (samples that don't represent true pattern)\n",
    "    in your training dataset.</li>\n",
    "<li>When model is more flexible, it is prone to overfitting</li>\n",
    "<li>Regularization shrinks the coefficients (parameter or slops) towards zero to discourages a more complex or flexible model, so as to avoid the risk of overfitting</li>\n",
    "    <li>Ridge and Lasso are two options </li>\n",
    "    <li>Regularization strength is provided by parameter <b>alpha</b></li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"final_cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['make', 'fuel-type', 'num-of-doors', 'body-style', 'drive-wheels',\n",
       "       'length', 'width', 'curb-weight', 'engine-size', 'highway-mpg',\n",
       "       'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create X and Y\n",
    "y = cars['price']\n",
    "X = cars.drop(columns=['price','make','fuel-type', 'num-of-doors', 'body-style', 'drive-wheels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LinearRegression(normalize=True)\n",
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length                         10.48\n",
      "width                         528.78\n",
      "curb-weight                     4.88\n",
      "engine-size                    72.33\n",
      "highway-mpg                   -46.98\n"
     ]
    }
   ],
   "source": [
    "for t in zip(X.columns, lr_model.coef_):\n",
    "  print(f\"{t[0]:25s} {t[1]:10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE  :  22211616.794805497\n",
      "RMSE :  4712.920198221639\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(\"MSE  : \", mse)\n",
    "print(\"RMSE : \", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=2.0, normalize=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(normalize=True, alpha=2.0)\n",
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length                         68.77\n",
      "width                         445.98\n",
      "curb-weight                     2.06\n",
      "engine-size                    28.91\n",
      "highway-mpg                  -109.07\n"
     ]
    }
   ],
   "source": [
    "# Display coefficient for each column\n",
    "for t in zip(X.columns, ridge.coef_):\n",
    "  print(f\"{t[0]:25s} {t[1]:10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE  :  38913820.519167095\n",
      "RMSE :  6238.094301881552\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(\"MSE  : \", mse)\n",
    "print(\"RMSE : \", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=(50, 45, 40, 35, 25, 10), cv=5, normalize=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LassoCV(normalize = True, cv=5,alphas=(50,45,40,35,25,10))\n",
    "lm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length                          0.00\n",
      "width                         401.63\n",
      "curb-weight                     2.35\n",
      "engine-size                   107.86\n",
      "highway-mpg                   -96.49\n"
     ]
    }
   ],
   "source": [
    "# Display coefficient for each column\n",
    "for t in zip(X.columns, lm.coef_):\n",
    "  print(f\"{t[0]:25s} {t[1]:10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_[np.abs(lm.coef_) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a part of data for final testing \n",
    "y_test  = y[:50]\n",
    "X_test = X[:50]\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE  :  13878867.909706945\n",
      "RMSE :  3725.4352644633277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print(\"MSE  : \",mse)\n",
    "print(\"RMSE : \", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "r2score = r2_score(y_test,y_pred)\n",
    "print(f\"R2 Score: {r2score:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
